<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
  &lt;!-- This will override the default value set in baseof.html; i.e., "preston.io" in the original example-->
  CI Server &ndash; preston.io
</title>
    <link rel="stylesheet" href="https://blog.preston.io/css/style.css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700i&display=swap" rel="stylesheet">
    <link rel="shortcut icon" href="/favicon.png">
  </head>
  <body>
    <header>
  <div class="container">
    <strong><a href="/">preston.io</a></strong>
  </div>
</header>
    
    <div class="container">
      
  <h1>CI Server</h1>
  <h2></h2>
  <p>by Preston Pham &mdash; Jan 1</p>
  <hr/>

<h2 id="how-to-build-a-ci-server-in-go">How to build a ci server in go<a href="#how-to-build-a-ci-server-in-go" class="hanchor" ariaLabel="Anchor"> #&#xFE0E;</a> </h2>

<p>For my new blog, I wanted to have the same sort of developer experience as I do with most of my work projects. In most cases,
building and deploying are either automated or a single script. I didn&rsquo;t want to set up Jenkins or TeamCity or what have you.
I had a simpler set of requirements in mind.</p>

<p>My ideal workflow for a static blog would be: drafting content in markdown and pushing commits to git. Everything after that should be automated.</p>

<p>After thinking about this, I figured I could whip something together that does this easily. The basic idea is setting up a git webhook for pushes
and setting up a server to respond to them.</p>

<p>The server implementation should be simple:</p>

<ul>
<li>should listen to git pushes</li>
<li>on each push, it should rebuild static content and push to an s3 bucket</li>
<li>should support some basic diagnostics like listing deployments and seeing the output of each log</li>
</ul>

<p>After a bit of hacking I came up with <a href="https://github.com/prestonp/boop">boop</a>. This blog will cover
how I built boop. The server was written in Go and hosted on a single DigitalOcean droplet.</p>

<p>The droplet contains several virtual hosts behind a nginx reverse proxy. This is all coordinated with
docker and <a href="https://github.com/jwilder/nginx-proxy">https://github.com/jwilder/nginx-proxy</a>.</p>

<h3 id="setting-up-a-webhook">Setting up a webhook<a href="#setting-up-a-webhook" class="hanchor" ariaLabel="Anchor"> #&#xFE0E;</a> </h3>

<p>In github you can configure web hooks on key events. A web hook is just an http request typically
with some interesting set of data.</p>

<aside>
Sometimes services use hooks as a notification mechanism. One example might be uploading and encoding
a video file. This typically takes a long time to complete so most APIs serving this kind of work are asynchronous. Going off the
upload example, say a client makes an upload request. An async API would return immediately with an HTTP status code
202, indicating that the request was _received_, but not necessarily completed. 

If this was API was sync, the server would have to complete all the work first and _then_ respond. This could take minutes to hours depending
on the workload. Clearly not ideal. So, instead of having clients poll for state on async, clients could implement a hook to receive status updates.
</aside>

<p>I created a new repo on github and configured a webhook. I set a secret which is used to digitally sign the webhook (HMAC).</p>

<p>So to start off building our ci server we&rsquo;ll need to <em>listen</em> to webhooks. When a webhook request is received, we need to verify the HMAC.
Github specifies X-Hub-Signature header which is the HMAC hex digest of the payload body. To verify, just take the sha1 hash of the body with the aforementioned
HMAC secret. If the computed digest matches the header, then the webhook is legitimate.</p>

<p>This is pretty trivial to implement with crypto libs but I found a <a href="https://github.com/rjz/githubhook">lib</a> that already handles this.</p>

<h3 id="triger-deployments">Triger deployments<a href="#triger-deployments" class="hanchor" ariaLabel="Anchor"> #&#xFE0E;</a> </h3>

<p>When a webhook handler is invoked, I run a simple bash script to build the static content then sync it up to a s3 bucket.</p>

<pre><code>#! /bin/bash

set -x
rm -rf build

git clone --recursive git://github.com/prestonp/bloggo.git build

cd build

hugo

aws s3 sync ./public s3://blog.preston.io --region us-west-1
</code></pre>

<p>So, basically clone, build, push. As per one of the requirements, I wanted to be able to look back on logs in case
something goes wrong during <code>hugo</code> build. To do this, I set up logging out to a log file.</p>

<h3 id="api">API<a href="#api" class="hanchor" ariaLabel="Anchor"> #&#xFE0E;</a> </h3>

<p>The API only supports two operations:</p>

<p><code>GET /</code> - List all deployments as text/html</p>

<p><code>GET /log/:idx</code> - Fetch a specific log where :idx is the deployment number</p>

<p>There&rsquo;s a small bit of state that is recorded in-memory for all of the deployments. Things like when the
deployment started and ended, the status of the deployment (inprogress, success or fail).</p>

<p>To simplify the implementation I made the decision to store all this state in-memory. Restarting the service cleans the logs and metadata,
but I didn&rsquo;t need this to be a robust or scalable service. It would hardly see any traffic because it only needs to responds to changes I make on a repo.
So in-memory is completely fine.</p>

<p>Visit <a href="https://ci.preston.io">https://ci.preston.io</a> to see it in action.</p>

<h3 id="configuration">Configuration<a href="#configuration" class="hanchor" ariaLabel="Anchor"> #&#xFE0E;</a> </h3>

<p>The rest of the details are described in the Dockerfile and configuration is passed through
<code>docker run</code> environment variables. Most importantly you&rsquo;ll need your AWS credentials and your
GitHub HMAC secret.</p>

<p>Looking back on this, I wanted everything to be flexible and configurable but I ended up implementing
a very specific workflow (github -&gt; ci -&gt; s3). Abstracting out the different pieces to support alternative
triggers and would make this a more reusable project, but my original goal was simply automating my blog deployments.</p>

<p>To that end, building the blog and uploading takes about ~3 seconds. Another advantage of this system is being able
to just focus on content. As long as I have github access, I can just write markdown files and commit to create new entries.
No need to have hugo and an aws client installed everywhere. Just push and you&rsquo;re done.</p>


    
    
    
    <footer>
  preston
</footer>
  </body>
</html>